{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cw8jbDFPWTqF"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade openai wikipedia-api serpapi requests gtts onnx onnxruntime huggingface_hub streamlit amadeus faiss-cpu\n",
        "!pip install --upgrade langchain-openai\n",
        "!pip install --upgrade google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csxZsl9z3LYC"
      },
      "outputs": [],
      "source": [
        "%%writefile req.txt\n",
        "streamlit\n",
        "openai\n",
        "wikipedia-api\n",
        "faiss-cpu\n",
        "transformers\n",
        "sentence-transformers\n",
        "onnx\n",
        "onnxruntime\n",
        "numpy\n",
        "pillow\n",
        "moviepy\n",
        "gtts\n",
        "requests\n",
        "langchain\n",
        "langchain-openai\n",
        "amadeus\n",
        "graphviz\n",
        "seaborn\n",
        "scikit-learn\n",
        "matplotlib\n",
        "plotly\n",
        "gradio\n",
        "diffusers\n",
        "accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j0bNq0h03cxx"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODSeFTiaUbHi"
      },
      "outputs": [],
      "source": [
        "# from moviepy.editor import AudioClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuC9hcgqZAYL"
      },
      "outputs": [],
      "source": [
        "from serpapi import GoogleSearch\n",
        "print(\"‚úÖ GoogleSearch is imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKYQkWp3WWtc"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import wikipediaapi\n",
        "import serpapi\n",
        "import requests\n",
        "import gtts\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import huggingface_hub\n",
        "import streamlit\n",
        "import amadeus\n",
        "import faiss\n",
        "\n",
        "print(\"‚úÖ All libraries are installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJakQKMoW07T"
      },
      "outputs": [],
      "source": [
        "# Create necessary files\n",
        "!touch app.py travel_story.py config.py utils.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwW3-vX_9eSm"
      },
      "outputs": [],
      "source": [
        "%%writefile config.py\n",
        "\n",
        "import os\n",
        "from amadeus import Client\n",
        "import os\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# ‚úÖ Fetch API keys securely from environment variables\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"*****\")\n",
        "AMADEUS_API_KEY = os.getenv(\"AMADEUS_API_KEY\", \"*****\")\n",
        "AMADEUS_API_SECRET = os.getenv(\"AMADEUS_API_SECRET\", \"*****\")\n",
        "GOOGLE_MAPS_API_KEY = os.getenv(\"GOOGLE_MAPS_API_KEY\", \"*****\")\n",
        "WEATHER_API_KEY = os.getenv(\"WEATHER_API_KEY\", \"*****\")\n",
        "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\", \"*****\")\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\", \"*****\")\n",
        "\n",
        "# ‚úÖ Initialize Amadeus Client\n",
        "\n",
        "amadeus = Client(client_id=AMADEUS_API_KEY, client_secret=AMADEUS_API_SECRET)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXJlvIf-9qo_"
      },
      "outputs": [],
      "source": [
        "# from config import OPENAI_API_KEY\n",
        "\n",
        "# print(OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAIbWp1GYn_U"
      },
      "source": [
        "# **Write utils.py (Helper Functions for API Calls)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOZmyouRX3O1"
      },
      "outputs": [],
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import requests\n",
        "from config import OPENAI_API_KEY, GOOGLE_MAPS_API_KEY, WEATHER_API_KEY, AMADEUS_API_KEY, AMADEUS_API_SECRET, llm\n",
        "from amadeus import Client, ResponseError\n",
        "import os\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import re\n",
        "import faiss\n",
        "import numpy as np\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.in_memory import InMemoryDocstore  # ‚úÖ Required for FAISS Storage\n",
        "from langchain.schema import Document\n",
        "\n",
        "amadeus = Client(client_id=AMADEUS_API_KEY, client_secret=AMADEUS_API_SECRET)\n",
        "\n",
        "# ‚úÖ Initialize OpenAI Embedding Model\n",
        "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "# ‚úÖ FAISS Setup\n",
        "dimension = 1536  # Ensure embedding dimensions match OpenAI embeddings\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "docstore = InMemoryDocstore({})\n",
        "index_to_docstore_id = {}\n",
        "\n",
        "vector_store = FAISS(embedding_model, faiss_index, docstore, index_to_docstore_id)\n",
        "\n",
        "# ‚úÖ Fetch Travel Data\n",
        "def fetch_travel_data(destination):\n",
        "    \"\"\"Retrieve real-time travel-related information from APIs.\"\"\"\n",
        "\n",
        "    print(f\"Fetching travel data for {destination}...\")\n",
        "\n",
        "    # ‚úÖ Wikipedia Data\n",
        "    wiki_url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{destination.replace(' ', '_')}\"\n",
        "    wiki_response = requests.get(wiki_url)\n",
        "    wiki_data = wiki_response.json().get(\"extract\", \"No data available.\") if wiki_response.status_code == 200 else \"No data available.\"\n",
        "\n",
        "    # ‚úÖ Google Places Data\n",
        "    google_places_url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
        "    params = {\"query\": f\"top attractions in {destination}\", \"key\": GOOGLE_MAPS_API_KEY}\n",
        "    google_response = requests.get(google_places_url, params=params)\n",
        "\n",
        "    places_info = \"No places found.\"\n",
        "    if google_response.status_code == 200:\n",
        "        places = google_response.json().get(\"results\", [])\n",
        "        places_info = \"\\n\".join([f\"{p['name']} - {p.get('formatted_address', 'No address')}\" for p in places[:5]])\n",
        "\n",
        "    return f\"{wiki_data}\\n\\nTop Attractions:\\n{places_info}\"\n",
        "\n",
        "# ‚úÖ Update FAISS Index\n",
        "def update_faiss_index(destination):\n",
        "    \"\"\"Dynamically update FAISS index and store documents properly.\"\"\"\n",
        "\n",
        "    print(f\"üîÑ Updating FAISS index for {destination}...\")\n",
        "    travel_data = fetch_travel_data(destination)\n",
        "\n",
        "    # ‚úÖ Generate embeddings dynamically\n",
        "    doc_embedding = embedding_model.embed_documents([travel_data])\n",
        "    embedding_dim = len(doc_embedding[0])  # ‚úÖ Detect embedding dimension dynamically\n",
        "\n",
        "    global faiss_index, vector_store, docstore, index_to_docstore_id\n",
        "\n",
        "    if faiss_index.is_trained and faiss_index.ntotal > 0:\n",
        "        existing_dim = faiss_index.d\n",
        "        if existing_dim != embedding_dim:\n",
        "            print(f\"‚ö†Ô∏è FAISS dimension mismatch! Reinitializing FAISS to {embedding_dim} dimensions.\")\n",
        "            faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
        "            docstore = InMemoryDocstore({})\n",
        "            index_to_docstore_id = {}\n",
        "\n",
        "    else:\n",
        "        print(f\"‚úÖ Initializing FAISS with {embedding_dim} dimensions.\")\n",
        "        faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
        "        docstore = InMemoryDocstore({})\n",
        "        index_to_docstore_id = {}\n",
        "\n",
        "    # ‚úÖ Add new embeddings to FAISS\n",
        "    faiss_index.add(np.array(doc_embedding))\n",
        "\n",
        "    # ‚úÖ Store document properly in docstore\n",
        "    doc_id = str(faiss_index.ntotal - 1)\n",
        "    index_to_docstore_id[faiss_index.ntotal - 1] = doc_id\n",
        "    docstore._dict[doc_id] = Document(page_content=travel_data, metadata={\"doc_id\": doc_id})\n",
        "\n",
        "    # ‚úÖ Save FAISS Index\n",
        "    vector_store = FAISS(embedding_model, faiss_index, docstore, index_to_docstore_id)\n",
        "    vector_store.save_local(\"faiss_travel_index\")\n",
        "\n",
        "    print(f\"‚úÖ FAISS Index successfully updated with travel data for {destination}\")\n",
        "\n",
        "# ‚úÖ Retrieve Data using FAISS\n",
        "def retrieve_relevant_docs(query):\n",
        "    \"\"\"Retrieve relevant travel data from FAISS dynamically.\"\"\"\n",
        "\n",
        "    print(f\"üîç Retrieving relevant documents for query: {query}\")\n",
        "\n",
        "    # ‚úÖ Load FAISS index safely\n",
        "    vector_store = FAISS.load_local(\n",
        "        \"faiss_travel_index\",\n",
        "        OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY),\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "\n",
        "    retrieved_docs = vector_store.similarity_search_with_score(query, k=2)\n",
        "\n",
        "    if not retrieved_docs:\n",
        "        print(\"‚ùå No relevant documents found.\")\n",
        "        return \"No relevant documents found for your query.\"\n",
        "\n",
        "    print(f\"‚úÖ Relevant Documents Found: {retrieved_docs}\")\n",
        "    return \" \".join([doc.page_content for doc, _ in retrieved_docs])\n",
        "\n",
        "# ‚úÖ Generate AI Travel Plan using RAG\n",
        "def generate_travel_plan_rag(origin, destination, start_date, end_date, purpose):\n",
        "    \"\"\"Use RAG to generate a detailed travel plan dynamically.\"\"\"\n",
        "\n",
        "    print(\"üîÑ Generating AI Travel Plan using RAG...\")\n",
        "\n",
        "    # ‚úÖ Retrieve Travel Information from FAISS\n",
        "    context_info = retrieve_relevant_docs(f\"Best travel itinerary for {destination}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Create a detailed travel itinerary for {destination} from {origin} ({start_date} - {end_date}).\n",
        "    Purpose: {purpose}\n",
        "\n",
        "    Additional Travel Information:\n",
        "    {context_info}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content if hasattr(response, 'content') else str(response)\n",
        "\n",
        "# ‚úÖ Generate AI Travel Story using RAG\n",
        "def generate_travel_story_rag(origin, destination, start_date, end_date, purpose):\n",
        "    \"\"\"Use RAG to generate a travel story dynamically.\"\"\"\n",
        "\n",
        "    print(\"üîÑ Generating AI Travel Story using RAG...\")\n",
        "\n",
        "    # ‚úÖ Retrieve Travel Information from FAISS\n",
        "    context_info = retrieve_relevant_docs(f\"Best places to visit in {destination} for {purpose}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Create a compelling travel story about visiting {destination} from {origin} ({start_date} - {end_date}).\n",
        "    Purpose: {purpose}\n",
        "\n",
        "    Additional Travel Information:\n",
        "    {context_info}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content if hasattr(response, 'content') else str(response)\n",
        "\n",
        "\n",
        "# ‚úÖ Function to fetch latitude & longitude\n",
        "def get_lat_lng(location):\n",
        "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
        "    params = {\"address\": location, \"key\": GOOGLE_MAPS_API_KEY}\n",
        "    response = requests.get(url, params=params).json()\n",
        "    if \"results\" in response and response[\"results\"]:\n",
        "        location_data = response[\"results\"][0][\"geometry\"][\"location\"]\n",
        "        return location_data[\"lat\"], location_data[\"lng\"]\n",
        "    return None, None\n",
        "\n",
        "# ‚úÖ Function to fetch tourist attractions\n",
        "def fetch_tourist_attractions(location, top_n=5):\n",
        "    lat, lng = get_lat_lng(location)\n",
        "    if not lat or not lng:\n",
        "        return \"Could not determine the exact location.\"\n",
        "\n",
        "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
        "    params = {\"location\": f\"{lat},{lng}\", \"radius\": 10000, \"type\": \"tourist_attraction\", \"key\": GOOGLE_MAPS_API_KEY}\n",
        "\n",
        "    response = requests.get(url, params=params).json()\n",
        "    if \"results\" in response:\n",
        "        return [f\"{t['name']} ({t.get('rating', 'No rating')}‚≠ê)\" for t in response[\"results\"][:top_n]]\n",
        "    return \"No tourist attractions found.\"\n",
        "\n",
        "# ‚úÖ Function to fetch restaurants\n",
        "def fetch_restaurants(location, purpose, top_n=5):\n",
        "    lat, lng = get_lat_lng(location)\n",
        "    if not lat or not lng:\n",
        "        return \"Could not determine the exact location.\"\n",
        "\n",
        "    keyword = {\n",
        "        \"Leisure\": \"casual dining\",\n",
        "        \"Business\": \"fine dining\",\n",
        "        \"Family\": \"family-friendly\",\n",
        "        \"Adventure\": \"unique cuisine\",\n",
        "        \"Romantic\": \"romantic restaurant\"\n",
        "    }.get(purpose, \"restaurant\")\n",
        "\n",
        "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
        "    params = {\"location\": f\"{lat},{lng}\", \"radius\": 5000, \"type\": \"restaurant\", \"keyword\": keyword, \"key\": GOOGLE_MAPS_API_KEY}\n",
        "\n",
        "    response = requests.get(url, params=params).json()\n",
        "    if \"results\" in response:\n",
        "        return [f\"{r['name']} ({r.get('rating', 'No rating')}‚≠ê)\" for r in response[\"results\"][:top_n]]\n",
        "    return \"No restaurants found.\"\n",
        "\n",
        "# ‚úÖ Function to fetch real-time weather details\n",
        "def fetch_weather(city):\n",
        "    url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
        "    params = {\"q\": city, \"appid\": WEATHER_API_KEY, \"units\": \"metric\"}\n",
        "    response = requests.get(url, params=params).json()\n",
        "    if \"weather\" in response and \"main\" in response:\n",
        "        return f\"{response['weather'][0]['description'].capitalize()}, {response['main']['temp']}¬∞C\"\n",
        "    return \"Weather data not available.\"\n",
        "\n",
        "def get_airport_code(city_name):\n",
        "    \"\"\"\n",
        "    Convert a city name to an airport code using the Amadeus API.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = amadeus.reference_data.locations.get(\n",
        "            keyword=city_name,\n",
        "            subType='AIRPORT'\n",
        "        )\n",
        "        # Extract the airport code from the response\n",
        "        for location in response.data:\n",
        "            if location['subType'] == 'AIRPORT':\n",
        "                return location['iataCode']\n",
        "        return None\n",
        "    except ResponseError as error:\n",
        "        print(f\"Error fetching airport code for {city_name}: {error}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Helper Function to get full airline names from its codes using OpenAI\n",
        "def get_airline_full_name(airline_code):\n",
        "    prompt = f\"Please provide only the full name for the airline '{airline_code}'.\"\n",
        "    response = llm([HumanMessage(content=prompt)])\n",
        "    return response.content.strip() if response else airline_code  # Return the code if response is empty\n",
        "\n",
        "def format_duration(iso_duration):\n",
        "    match = re.match(r'PT(?:(\\d+)H)?(?:(\\d+)M)?', iso_duration)\n",
        "    hours = match.group(1) if match.group(1) else \"0\"\n",
        "    minutes = match.group(2) if match.group(2) else \"0\"\n",
        "    return f\"{int(hours)} hours {int(minutes)} minutes\"\n",
        "\n",
        "# Function to fetch Flights information\n",
        "def fetch_flight_details(origin, destination, start_data, return_date=None, max_price=None, airline_name =None):\n",
        "    try:\n",
        "        origin_code = get_airport_code(origin)\n",
        "        destination_code = get_airport_code(destination)\n",
        "        # Set a high default max_price if not provided\n",
        "        max_price = max_price if max_price else 20000\n",
        "        params = {\n",
        "            \"originLocationCode\": origin_code,\n",
        "            \"destinationLocationCode\": destination_code,\n",
        "            \"departureDate\": start_data,\n",
        "            \"adults\": 1,\n",
        "            \"maxPrice\": max_price\n",
        "        }\n",
        "\n",
        "        if return_date:\n",
        "            params[\"returnDate\"] = return_date  # Include return date for round-trip flights\n",
        "\n",
        "        # Fetch flights from Amadeus API\n",
        "        response = amadeus.shopping.flight_offers_search.get(**params)\n",
        "        flights = response.data\n",
        "\n",
        "        if flights:\n",
        "            result = []\n",
        "            for flight in flights[:5]:  # Limit to top 5 results\n",
        "                if float(flight['price']['total']) <= max_price:\n",
        "                    # Outbound flight details\n",
        "                    segments = flight['itineraries'][0]['segments']\n",
        "                    airline_code = segments[0]['carrierCode']\n",
        "                    airline = get_airline_full_name(airline_code)  # Get full airline name\n",
        "                    # Only add flights that match the specified airline, if provided\n",
        "                    if airline_name and airline and airline.lower() not in airline_name.lower():\n",
        "                        continue\n",
        "                    departure_time = segments[0]['departure']['at']\n",
        "                    arrival_time = segments[-1]['arrival']['at']\n",
        "                    flight_duration = format_duration(flight['itineraries'][0]['duration'])\n",
        "\n",
        "                    # Only include return details if a return date is provided\n",
        "                    if return_date and len(flight['itineraries']) > 1:\n",
        "                        return_segments = flight['itineraries'][1]['segments']\n",
        "                        return_departure_time = return_segments[0]['departure']['at']\n",
        "                        return_arrival_time = return_segments[-1]['arrival']['at']\n",
        "                        return_duration = format_duration(flight['itineraries'][1]['duration'])\n",
        "                        return_info = (\n",
        "                            f\"\\nReturn Departure: {return_departure_time}\\n\"\n",
        "                            f\"Return Arrival: {return_arrival_time}\\n\"\n",
        "                            f\"Return Duration: {return_duration}\\n\"\n",
        "                        )\n",
        "                    else:\n",
        "                        return_info = \"\"\n",
        "\n",
        "                    # Append both outbound and return information (if available) to results\n",
        "                    result.append(\n",
        "                        f\"Airline: {airline}\\nPrice: ${flight['price']['total']}\\n\"\n",
        "                        f\"Departure: {departure_time}\\nArrival: {arrival_time}\\n\"\n",
        "                        f\"Duration: {flight_duration}{return_info}\"\n",
        "                        \"\\n----------------------------------------\"\n",
        "                    )\n",
        "            return \"\\n\\n\".join(result) if result else \"No flights found within the budget.\"\n",
        "        return \"No flights found.\"\n",
        "    except ResponseError as error:\n",
        "        return f\"An error occurred: {error.response.result}\"\n",
        "\n",
        "# ‚úÖ Function to fetch hotels\n",
        "def fetch_hotels(location, top_n=5):\n",
        "    lat, lng = get_lat_lng(location)\n",
        "    if not lat or not lng:\n",
        "        return \"Could not determine the exact location.\"\n",
        "\n",
        "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
        "    params = {\"location\": f\"{lat},{lng}\", \"radius\": 5000, \"type\": \"lodging\", \"key\": GOOGLE_MAPS_API_KEY}\n",
        "\n",
        "    response = requests.get(url, params=params).json()\n",
        "    if \"results\" in response:\n",
        "        return [f\"{h['name']} ({h.get('rating', 'No rating')}‚≠ê)\" for h in response[\"results\"][:top_n]]\n",
        "    return \"No hotels found.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H93M6UNtO0Z1",
        "outputId": "4414b7fe-aa07-4e33-ee0a-05f670e5d9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring Inputs:   0%|          | 0/1 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "Scoring Inputs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done! Scores saved to '/content/wandertales_scores.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load your input JSON\n",
        "with open(\"/content/wandertales_input.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# If it's a dictionary with a key like 'data'\n",
        "if isinstance(data, dict):\n",
        "    data = data.get(\"data\", [data])\n",
        "\n",
        "# Compute perplexity\n",
        "def compute_perplexity(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    return torch.exp(outputs.loss).item()\n",
        "\n",
        "# Compute logit entropy (average over tokens)\n",
        "def compute_entropy(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits  # (batch_size, seq_len, vocab_size)\n",
        "        probs = F.softmax(logits, dim=-1)  # (batch_size, seq_len, vocab_size)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        entropy = -(probs * log_probs).sum(dim=-1)  # (batch_size, seq_len)\n",
        "        mean_entropy = entropy.mean().item()  # average over sequence\n",
        "    return mean_entropy\n",
        "\n",
        "# Evaluate each input\n",
        "results = []\n",
        "for entry in tqdm(data, desc=\"Scoring Inputs\"):\n",
        "    text = entry.get(\"text\") or entry.get(\"content\") or str(entry)\n",
        "    ppl = compute_perplexity(text)\n",
        "    entropy = compute_entropy(text)\n",
        "    results.append({\"text\": text, \"perplexity\": ppl, \"entropy\": entropy})\n",
        "\n",
        "# Save results\n",
        "with open(\"/content/wandertales_scores.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"Done! Scores saved to '/content/wandertales_scores.json'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGfRny-Z5gc"
      },
      "source": [
        "# **Write travel_story.py (AI-Powered Travel Story & Video Generation)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtPSz65JZXj2"
      },
      "outputs": [],
      "source": [
        "%%writefile travel_story.py\n",
        "\n",
        "import openai\n",
        "import requests\n",
        "import wikipediaapi\n",
        "import io\n",
        "import time\n",
        "import onnx\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "# from moviepy.editor import *  # For video editing\n",
        "from gtts import gTTS  # For text-to-speech\n",
        "from onnxruntime import InferenceSession\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from config import OPENAI_API_KEY # Import the latest API key from config.py\n",
        "from config import llm, amadeus\n",
        "import openai\n",
        "import faiss\n",
        "from utils import update_faiss_index , generate_travel_story_rag, generate_travel_plan_rag, retrieve_relevant_docs\n",
        "\n",
        "# ‚úÖ Ensure OpenAI API is using the latest key\n",
        "openai.api_key = OPENAI_API_KEY  # This ensures the latest key is used every time\n",
        "\n",
        "# ‚úÖ Initialize OpenAI Client\n",
        "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# ‚úÖ Wikipedia API Setup\n",
        "wiki = wikipediaapi.Wikipedia(user_agent=\"MyTravelApp/1.0\", language=\"en\")\n",
        "\n",
        "# ‚úÖ Function to fetch travel data from Wikipedia\n",
        "def get_wikipedia_summary(place):\n",
        "    page = wiki.page(place)\n",
        "    return page.summary[:500] if page.exists() else \"No Wikipedia summary found.\"\n",
        "\n",
        "def generate_travel_story(origin, destination, purpose, start_date, end_date):\n",
        "    # wikipedia_info = get_wikipedia_summary(destination)\n",
        "    update_faiss_index(destination)\n",
        "    wikipedia_info = generate_travel_story_rag(origin, destination, start_date, end_date, purpose)\n",
        "\n",
        "    purpose_templates = {\n",
        "      \"leisure\": f\"You are about to embark on a relaxing leisure trip starting from {origin} to {destination} from {start_date} to {end_date}. Describe your journey, including your departure experience, flight details, and how you arrive at {destination}. Highlight the famous landmarks, scenic parks, and peaceful experiences during your visit.\",\n",
        "\n",
        "      \"food\": f\"As a food lover, you're traveling from {origin} to {destination} from {start_date} to {end_date} to explore its vibrant culinary scene. Describe the unique food experiences from the departure airport to your destination, including delicious street food, high-end restaurants, and bustling food markets in {destination}. Mention iconic caf√©s and dishes travelers should not miss.\",\n",
        "\n",
        "      \"adventure\": f\"You're departing from {origin} to {destination} for an adrenaline-filled adventure from {start_date} to {end_date}. Describe your travel experience, flight, and arrival at {destination}. Highlight the thrilling activities such as hiking, surfing, skydiving, and other outdoor experiences that make this trip exhilarating.\",\n",
        "\n",
        "      \"business\": f\"You're traveling from {origin} to {destination} for a business trip from {start_date} to {end_date}. Describe your departure from {origin}, your flight experience, and how you arrive at {destination}. Detail your meetings, networking events, and the city's corporate atmosphere. Also, mention after-hours dining or sightseeing to balance work and leisure.\",\n",
        "\n",
        "      \"romantic\": f\"You're setting off from {origin} to {destination} for a romantic getaway from {start_date} to {end_date}. Describe the journey from {origin}, including your travel experience and how you and your partner arrive at {destination}. Highlight intimate dinners, scenic walks, breathtaking sunset views, and special moments shared during this trip.\",\n",
        "\n",
        "      \"spiritual\": f\"You're traveling from {origin} to {destination} for a spiritual retreat from {start_date} to {end_date}. Describe your departure experience from {origin}, flight details, and arrival at {destination}. Mention meditation spots, temples, churches, and peaceful landscapes that provide a sense of tranquility and reflection.\",\n",
        "\n",
        "      \"family\": f\"You're taking a family trip from {origin} to {destination} from {start_date} to {end_date}, creating memorable bonding moments. Describe your journey, including how you and your family prepare for the trip, your flight experience, and your arrival at {destination}. Highlight amusement parks, kid-friendly attractions, and activities that make this a joyful and unforgettable experience for everyone.\"\n",
        "    }\n",
        "\n",
        "\n",
        "    purpose_prompt = purpose_templates.get(purpose, purpose_templates[\"leisure\"])\n",
        "\n",
        "    full_prompt = f\"\"\"\n",
        "    {purpose_prompt}\n",
        "\n",
        "    Be immersive, engaging, and detailed. Use vivid descriptions and include unique aspects of {destination}.\n",
        "\n",
        "    Wikipedia Summary: {wikipedia_info}\n",
        "\n",
        "    Travel Story:\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(full_prompt)\n",
        "    return response.content if hasattr(response, 'content') else str(response)\n",
        "\n",
        "# ‚úÖ Function to generate a travel plan\n",
        "def generate_travel_plan(origin, destination, start_date, end_date, purpose):\n",
        "    update_faiss_index(destination)\n",
        "    travel_plan_context = generate_travel_plan_rag(origin, destination, start_date, end_date, purpose)\n",
        "    prompt = f\"\"\"\n",
        "    Generate a detailed travel itinerary for a trip starting from {origin} to {destination} from {start_date} to {end_date} for {purpose}. Use {travel_plan_context} as a reference.\n",
        "\n",
        "    Include the following details:\n",
        "    - **Departure details** from {origin}, including flight or transportation options.\n",
        "    - **Arrival experience** in {destination} and first impressions.\n",
        "    - **Accommodation recommendations** suitable for {purpose}.\n",
        "    - **Top attractions** in {destination} that match {purpose}.\n",
        "    - **Food and dining recommendations**, including famous restaurants.\n",
        "    - **Local transportation options** to navigate within {destination}.\n",
        "    - **Return trip details** from {destination} back to {origin} (if applicable).\n",
        "\n",
        "    Ensure the itinerary is engaging and structured as a day-by-day plan.\n",
        "\n",
        "    Travel Itinerary:\n",
        "    \"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content if hasattr(response, 'content') else str(response)\n",
        "\n",
        "# ‚úÖ Function to extract day-wise highlights\n",
        "def extract_daywise_highlights(travel_plan):\n",
        "    days = travel_plan.split(\"Day \")[1:]\n",
        "    daywise_highlights = {}\n",
        "    for day in days:\n",
        "        lines = day.split(\"\\n\")\n",
        "        day_number = lines[0].strip()\n",
        "        activities = \". \".join([line.strip() for line in lines[1:] if line.strip()])\n",
        "        daywise_highlights[day_number] = activities\n",
        "    return daywise_highlights\n",
        "\n",
        "# ‚úÖ Function to generate travel images per day's activity\n",
        "def generate_travel_images(daywise_highlights, destination):\n",
        "    image_urls = {}\n",
        "    for day, activities in daywise_highlights.items():\n",
        "        prompt = f\"Generate an ultra-HD image representing {activities} in {destination}.\"\n",
        "        response = client.images.generate(\n",
        "            model=\"dall-e-3\", prompt=prompt, n=1, size=\"1024x1024\"\n",
        "        )\n",
        "        image_urls[day] = response.data[0].url\n",
        "    return image_urls\n",
        "\n",
        "# ‚úÖ Function to generate a voice-over for the itinerary\n",
        "def generate_voiceover(travel_plan, output_audio=\"travel_narration.mp3\"):\n",
        "    tts = gTTS(text=travel_plan, lang=\"en\", slow=False)\n",
        "    tts.save(output_audio)\n",
        "    return output_audio\n",
        "\n",
        "# ‚úÖ Function to create an animated travel video based on day-wise images\n",
        "def create_travel_video(image_urls, narration_audio, output_video=\"travel_story.mp4\"):\n",
        "    audio_clip = AudioFileClip(narration_audio)\n",
        "    total_audio_duration = audio_clip.duration\n",
        "    num_days = len(image_urls)\n",
        "    image_duration = total_audio_duration / num_days  # Divide equally among days\n",
        "\n",
        "    image_clips = []\n",
        "    for day, url in image_urls.items():\n",
        "        response = requests.get(url)\n",
        "        image = Image.open(io.BytesIO(response.content))\n",
        "        image_path = f\"travel_image_{day}.jpg\"\n",
        "        image.save(image_path)\n",
        "\n",
        "        clip = ImageClip(image_path, duration=image_duration).set_fps(24)\n",
        "        clip = clip.resize(lambda t: 1 + 0.01 * t)  # Slow zoom-in effect\n",
        "        image_clips.append(clip)\n",
        "\n",
        "    video_clip = concatenate_videoclips(image_clips, method=\"compose\")\n",
        "    video_clip = video_clip.set_audio(audio_clip)\n",
        "    video_clip.write_videofile(output_video, codec=\"libx264\", fps=24, audio_codec=\"aac\")\n",
        "    print(\"üé¨ Personalized travel video created successfully!\")\n",
        "\n",
        "# ‚úÖ Execution for Testing\n",
        "if __name__ == \"__main__\":\n",
        "    origin = \"New York\"\n",
        "    destination = \"Hyderabad\"\n",
        "    purpose = \"Family\"\n",
        "    start_date = \"2025-04-15\"\n",
        "    end_date = \"2025-04-20\"\n",
        "\n",
        "    print(\"üìÖ Generating Travel Plan...\")\n",
        "    travel_plan = generate_travel_plan(origin, destination, start_date, end_date, purpose)\n",
        "    print(f\"üìù Travel Plan:\\n{travel_plan}\")\n",
        "\n",
        "    # ‚úÖ Extract day-wise activities\n",
        "    daywise_highlights = extract_daywise_highlights(travel_plan)\n",
        "\n",
        "    print(\"üîÑ Fetching data and generating travel story...\")\n",
        "    travel_story_text = generate_travel_story(origin, destination, purpose, start_date, end_date)\n",
        "    print(f\"üìñ Travel Story:\\n{travel_story_text}\")\n",
        "\n",
        "    print(\"üñº Generating Travel Images...\")\n",
        "    image_urls = generate_travel_images(daywise_highlights, destination)\n",
        "    print(f\"Generated Images: {image_urls}\")\n",
        "\n",
        "    print(\"üé§ Generating voiceover...\")\n",
        "    narration_file = generate_voiceover(travel_story_text)\n",
        "\n",
        "    print(\"üé• Creating travel video...\")\n",
        "    travel_video = create_travel_video(image_urls, narration_file)\n",
        "    print(f\"‚úÖ Travel video saved as {travel_video}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hywZf_OJMCAu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load your input JSON\n",
        "with open(\"/content/wandertales_input.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# If it's a dictionary with a key like 'data'\n",
        "if isinstance(data, dict):\n",
        "    data = data.get(\"data\", [data])\n",
        "\n",
        "# Compute perplexity\n",
        "def compute_perplexity(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    return torch.exp(outputs.loss).item()\n",
        "\n",
        "# Compute logit entropy (average over tokens)\n",
        "def compute_entropy(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits  # (batch_size, seq_len, vocab_size)\n",
        "        probs = F.softmax(logits, dim=-1)  # (batch_size, seq_len, vocab_size)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        entropy = -(probs * log_probs).sum(dim=-1)  # (batch_size, seq_len)\n",
        "        mean_entropy = entropy.mean().item()  # average over sequence\n",
        "    return mean_entropy\n",
        "\n",
        "# Evaluate each input\n",
        "results = []\n",
        "for entry in tqdm(data, desc=\"Scoring Inputs\"):\n",
        "    text = entry.get(\"text\") or entry.get(\"content\") or str(entry)\n",
        "    ppl = compute_perplexity(text)\n",
        "    entropy = compute_entropy(text)\n",
        "    results.append({\"text\": text, \"perplexity\": ppl, \"entropy\": entropy})\n",
        "\n",
        "# Save results\n",
        "with open(\"/content/wandertales_scores.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"Done! Scores saved to '/content/wandertales_scores.json'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_6GvknqdZt0"
      },
      "source": [
        "# **Write app.py (Streamlit UI)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFv-DW57bNRn"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from travel_story import generate_travel_story, generate_voiceover, create_travel_video, generate_travel_plan, generate_travel_images, extract_daywise_highlights\n",
        "from utils import fetch_weather, fetch_tourist_attractions, fetch_flight_details, fetch_restaurants, fetch_hotels\n",
        "from config import llm  # Ensure llm is imported for LLM calls\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from moviepy.editor import AudioFileClip\n",
        "\n",
        "# Set up Streamlit Page\n",
        "st.set_page_config(page_title=\"‚úàÔ∏è AI Travel Planner\", layout=\"wide\")\n",
        "\n",
        "st.title(\"‚úàÔ∏è AI Travel Planner üè®\")\n",
        "\n",
        "# Sidebar Inputs\n",
        "st.sidebar.title(\"Plan Your Trip üó∫\")\n",
        "origin = st.sidebar.text_input(\"Enter Origin City\", \"New York\")\n",
        "destination = st.sidebar.text_input(\"Enter Destination\", \"Paris\")\n",
        "start_date = st.sidebar.date_input(\"Start Date\")\n",
        "end_date = st.sidebar.date_input(\"End Date\")\n",
        "purpose = st.sidebar.selectbox(\"Purpose of Visit\", [\"Leisure\", \"Business\", \"Adventure\", \"Romantic\", \"Family\"])\n",
        "\n",
        "# Initialize session state for storing travel plan and conversation\n",
        "if \"travel_plan\" not in st.session_state:\n",
        "    st.session_state.travel_plan = None\n",
        "    st.session_state.travel_details = {}\n",
        "\n",
        "if \"conversation\" not in st.session_state:\n",
        "    st.session_state.conversation = []\n",
        "\n",
        "# Keep track of message processing state\n",
        "if \"message_to_process\" not in st.session_state:\n",
        "    st.session_state.message_to_process = None\n",
        "\n",
        "# Generate Travel Plan & Fetch Details\n",
        "if st.sidebar.button(\"Generate Travel Plan & Details\", key=\"gen_plan_btn\"):\n",
        "    with st.spinner(\"üîÑ Generating AI travel plan & fetching details...\"):\n",
        "        travel_plan_text = generate_travel_plan(origin, destination, start_date, end_date, purpose)\n",
        "        weather_info = fetch_weather(destination)\n",
        "        tourist_attractions = fetch_tourist_attractions(destination)\n",
        "        restaurants = fetch_restaurants(destination, purpose)\n",
        "        hotels = fetch_hotels(destination)\n",
        "        flights = fetch_flight_details(origin, destination, start_date, return_date=None, max_price=None, airline_name=None)\n",
        "\n",
        "        # Store the travel plan in session state for the chatbot to use\n",
        "        st.session_state.travel_plan = travel_plan_text\n",
        "        st.session_state.travel_details = {\n",
        "            \"weather\": weather_info,\n",
        "            \"attractions\": tourist_attractions,\n",
        "            \"restaurants\": restaurants,\n",
        "            \"hotels\": hotels,\n",
        "            \"flights\": flights\n",
        "        }\n",
        "\n",
        "    # Display the generated plan and details\n",
        "    st.subheader(\"üìÖ Your AI-Generated Travel Plan\")\n",
        "    st.write(travel_plan_text)\n",
        "    st.subheader(f\"üå¶ Weather Forecast in {destination}\")\n",
        "    st.write(weather_info)\n",
        "    st.subheader(f\"üèõ Top Attractions in {destination}\")\n",
        "    st.write(tourist_attractions)\n",
        "    st.subheader(f\"üçΩ Best Restaurants in {destination}\")\n",
        "    st.write(restaurants)\n",
        "    st.subheader(f\"üè® Recommended Hotels in {destination}\")\n",
        "    st.write(hotels)\n",
        "    st.subheader(f\"‚úàÔ∏è Flights from {origin} to {destination}\")\n",
        "    st.write(flights)\n",
        "\n",
        "# Generate Travel Story & Voiceover\n",
        "if st.sidebar.button(\"Generate Story & Voiceover\", key=\"gen_story_btn\"):\n",
        "    with st.spinner(\"üîÑ Generating AI travel story...\"):\n",
        "        travel_story_text = generate_travel_story(origin, destination, purpose, start_date, end_date)\n",
        "        narration_audio = generate_voiceover(travel_story_text)\n",
        "\n",
        "    st.subheader(\"üìñ Your AI-Generated Travel Story\")\n",
        "    st.write(travel_story_text)\n",
        "    st.subheader(\"üé§ AI Voiceover\")\n",
        "    st.audio(narration_audio)\n",
        "\n",
        "# Generate Images & Video\n",
        "if st.sidebar.button(\"Generate Images & Video\", key=\"gen_media_btn\"):\n",
        "    with st.spinner(\"üñº Generating Travel Images...\"):\n",
        "        travel_plan_text = generate_travel_plan(origin, destination, start_date, end_date, purpose)\n",
        "        daywise_highlights = extract_daywise_highlights(travel_plan_text)\n",
        "        travel_images = generate_travel_images(daywise_highlights, destination)\n",
        "    st.subheader(\"üñº View Destination Images\")\n",
        "    if travel_images:\n",
        "        for image_url in travel_images:\n",
        "            response = requests.get(image_url)\n",
        "            if response.status_code == 200:\n",
        "                image = Image.open(BytesIO(response.content))\n",
        "                st.image(image, caption=f\"A view of {destination}\", use_container_width=True)\n",
        "            else:\n",
        "                st.warning(\"‚ùå Unable to fetch image. Try again later.\")\n",
        "    else:\n",
        "        st.warning(\"‚ùå No images generated.\")\n",
        "\n",
        "    with st.spinner(\"üé• Creating AI Travel Video...\"):\n",
        "        travel_plan_text = generate_travel_plan(origin, destination, start_date, end_date, purpose)\n",
        "        daywise_highlights = extract_daywise_highlights(travel_plan_text)\n",
        "        travel_images = generate_travel_images(daywise_highlights, destination)\n",
        "        narration_audio = generate_voiceover(travel_plan_text)\n",
        "        travel_video = create_travel_video(travel_images, narration_audio)\n",
        "    st.subheader(\"üé• AI-Generated Travel Video\")\n",
        "    if travel_video:\n",
        "        st.video(travel_video)\n",
        "    else:\n",
        "        st.warning(\"‚ùå Video generation failed.\")\n",
        "\n",
        "st.success(\"‚úÖ AI Travel Planner is ready!\")\n",
        "\n",
        "# =======================\n",
        "# Interactive Chat Section\n",
        "# =======================\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.header(\"ü§ñ Chat with Your Travel Planner\")\n",
        "st.write(\"Ask questions about your trip or request modifications to your plan.\")\n",
        "\n",
        "def update_message_to_process():\n",
        "# First, check if there's a message to process from the previous run\n",
        "    if st.session_state.message_to_process:\n",
        "        with st.spinner(\"Processing your message...\"):\n",
        "            # Get the message to process\n",
        "            message = st.session_state.message_to_process\n",
        "\n",
        "            # Add user message to conversation\n",
        "            st.session_state.conversation.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "            # Build context for the LLM based on existing travel information\n",
        "            context = f\"Origin: {origin}, Destination: {destination}, Dates: {start_date} to {end_date}, Purpose: {purpose}\"\n",
        "\n",
        "            # Create a comprehensive system prompt that includes the base travel plan\n",
        "            travel_plan = st.session_state.travel_plan if st.session_state.travel_plan else \"No travel plan has been generated yet.\"\n",
        "            travel_details = st.session_state.travel_details\n",
        "\n",
        "            system_prompt = f\"\"\"You are an AI travel assistant helping a user with their trip.\n",
        "\n",
        "            TRIP DETAILS:\n",
        "            - Origin: {origin}\n",
        "            - Destination: {destination}\n",
        "            - Dates: {start_date} to {end_date}\n",
        "            - Purpose: {purpose}\n",
        "\n",
        "            BASE TRAVEL PLAN:\n",
        "            {travel_plan}\n",
        "\n",
        "            ADDITIONAL INFORMATION:\n",
        "            - Weather: {travel_details.get('weather', 'Not available')}\n",
        "            - Top Attractions: {travel_details.get('attractions', 'Not available')}\n",
        "            - Restaurants: {travel_details.get('restaurants', 'Not available')}\n",
        "            - Hotels: {travel_details.get('hotels', 'Not available')}\n",
        "            - Flights: {travel_details.get('flights', 'Not available')}\n",
        "\n",
        "            INSTRUCTIONS:\n",
        "            - Remember all details about the user's trip when answering questions\n",
        "            - Be concise but informative in your responses\n",
        "            - If the user asks about information not in the plan, respond with relevant suggestions\n",
        "            - If the user wants to modify their plan, acknowledge this and explain how the modification fits with the overall trip\n",
        "            \"\"\"\n",
        "\n",
        "            # Create messages array for the LLM\n",
        "            messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "            # Add conversation history to messages\n",
        "            for msg in st.session_state.conversation:\n",
        "                if msg[\"role\"] != \"system\":  # Avoid duplicate system messages\n",
        "                    messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
        "\n",
        "            # Generate assistant response using the LLM\n",
        "            try:\n",
        "                # Using the llm in a way that works with both older and newer LLM interfaces\n",
        "                if hasattr(llm, 'chat'):\n",
        "                    # For newer LLM interfaces that use the chat method\n",
        "                    response = llm.chat(messages)\n",
        "                    assistant_response = response.content if hasattr(response, \"content\") else str(response)\n",
        "                else:\n",
        "                    # For older LLM interfaces or those using direct invoke\n",
        "                    full_prompt = system_prompt + \"\\n\\n\" + \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in messages if m['role'] != \"system\"])\n",
        "                    response = llm.invoke(full_prompt)\n",
        "                    assistant_response = response.content if hasattr(response, \"content\") else str(response)\n",
        "\n",
        "                # Add assistant response to conversation history\n",
        "                st.session_state.conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error generating response: {str(e)}\")\n",
        "\n",
        "            # Clear the message to process\n",
        "            st.session_state.message_to_process = None\n",
        "\n",
        "# Display the conversation history\n",
        "st.subheader(\"üí¨ Your Conversation\")\n",
        "for message in st.session_state.conversation:\n",
        "    if message[\"role\"] == \"user\":\n",
        "        st.markdown(f\"**You:** {message['content']}\")\n",
        "    else:\n",
        "        st.markdown(f\"**Planner:** {message['content']}\")\n",
        "\n",
        "# # Input for user's message\n",
        "# user_input = st.text_input(\"Your message:\", key=\"chat_input\")\n",
        "# send_button = st.button(\"Send\", key=\"send_btn\")\n",
        "\n",
        "# if send_button and user_input:\n",
        "#     # Store the message to process in the next run\n",
        "#     st.session_state.message_to_process = user_input\n",
        "#     # # Clear the input\n",
        "#     # st.session_state.chat_input = \"\"\n",
        "#     update_message_to_process()\n",
        "\n",
        "# Initialize the key in session state if it doesn't exist\n",
        "if \"user_input\" not in st.session_state:\n",
        "    st.session_state.user_input = \"\"\n",
        "\n",
        "# Input for user's message - use a callback to handle submissions\n",
        "def submit_message():\n",
        "    if st.session_state.user_input.strip():\n",
        "        st.session_state.message_to_process = st.session_state.user_input\n",
        "        st.session_state.user_input = \"\"\n",
        "        update_message_to_process()\n",
        "\n",
        "# Create the text input with the callback\n",
        "user_input = st.text_input(\n",
        "    \"Your message:\",\n",
        "    key=\"user_input\",\n",
        "    on_change=submit_message\n",
        ")\n",
        "\n",
        "# # Add a send button that also triggers the same callback\n",
        "# if st.button(\"Send\", key=\"send_btn\"):\n",
        "#     submit_message()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3MU_fp01VvBW"
      },
      "outputs": [],
      "source": [
        "# from travel_story import generate_travel_story, generate_voiceover, create_travel_video, generate_travel_plan, generate_travel_images\n",
        "# from utils import fetch_weather, fetch_tourist_attractions, fetch_flight_details, fetch_restaurants, fetch_hotels\n",
        "# from config import llm\n",
        "\n",
        "\n",
        "# class SessionState:\n",
        "#     def __init__(self):\n",
        "#         self.conversation = []\n",
        "\n",
        "# # Initialize session state\n",
        "# session_state = SessionState()\n",
        "\n",
        "# travel_plan_text = generate_travel_plan(\"New York\", \"New Delhi\", \"2025-04-15\", \"2025-04-20\", \"Family\")\n",
        "# print(travel_plan_text)\n",
        "\n",
        "# def chatbot_loop():\n",
        "#     \"\"\"\n",
        "#     Simulates a chatbot interaction where users provide input,\n",
        "#     and the chatbot refines the travel plan iteratively.\n",
        "#     \"\"\"\n",
        "#     print(\"ü§ñ AI Travel Planner Chatbot\")\n",
        "#     print(\"Type 'exit' to stop the chat.\\n\")\n",
        "\n",
        "#     while True:\n",
        "#         user_input = input(\"You: \")\n",
        "#         if user_input.lower() == \"exit\":\n",
        "#             print(\"\\nChat ended.\")\n",
        "#             break\n",
        "\n",
        "#         # Append user message to conversation history\n",
        "#         session_state.conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "#         # Construct conversation context\n",
        "#         conversation_context = \"\\n\".join(\n",
        "#             [f\"{msg['role']}: {msg['content']}\" for msg in session_state.conversation]\n",
        "#         )\n",
        "#         # print(conversation_context)\n",
        "\n",
        "#         prompt = (\n",
        "#             f\"Below is the base travel plan:\\n{travel_plan_text}\\n\\n\"\n",
        "#             f\"And here is the conversation with the user:\\n{conversation_context}\\n\\n\"\n",
        "#             \"Based on the above, please respond to the user answering his queries.\"\n",
        "#         )\n",
        "\n",
        "#         # Mock LLM call (replace with actual LLM API call in production)\n",
        "#         ai_response = llm.invoke(prompt)\n",
        "\n",
        "#         # Append AI response to conversation history\n",
        "#         session_state.conversation.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "\n",
        "#         # Print the response\n",
        "#         print(f\"Planner: {ai_response}\\n\")\n",
        "\n",
        "\n",
        "# # Run the chatbot loop\n",
        "# chatbot_loop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hKk65nvjqJx"
      },
      "outputs": [],
      "source": [
        "%%writefile verify_imports.py\n",
        "\n",
        "import os\n",
        "\n",
        "# ‚úÖ Check if all necessary files exist\n",
        "required_files = [\"config.py\", \"utils.py\", \"travel_story.py\", \"app.py\"]\n",
        "missing_files = [file for file in required_files if not os.path.exists(file)]\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"‚ùå ERROR: Missing files: {missing_files}. Ensure all required files are present.\")\n",
        "else:\n",
        "    print(\"‚úÖ All necessary files exist.\")\n",
        "\n",
        "# ‚úÖ Verify `config.py` imports\n",
        "try:\n",
        "    from config import google_maps_api_key, serpapi_key, WEATHER_API_KEY\n",
        "    print(\"‚úÖ Successfully imported API keys from config.py\")\n",
        "    print(f\"Google Maps API Key: {google_maps_api_key[:5]}******\")\n",
        "    print(f\"SerpAPI Key: {serpapi_key[:5]}******\")\n",
        "    print(f\"Weather API Key: {weather_api_key[:5]}******\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"‚ùå ERROR: 'config.py' not found.\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå ERROR: Could not import variables from 'config.py'.\")\n",
        "\n",
        "# ‚úÖ Verify `utils.py` imports\n",
        "try:\n",
        "    from utils import get_lat_lng, fetch_restaurants, fetch_weather\n",
        "    print(\"‚úÖ Successfully imported functions from utils.py\")\n",
        "    print(f\"get_lat_lng function exists: {callable(get_lat_lng)}\")\n",
        "    print(f\"fetch_restaurants function exists: {callable(fetch_restaurants)}\")\n",
        "    print(f\"fetch_weather function exists: {callable(fetch_weather)}\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"‚ùå ERROR: 'utils.py' not found.\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå ERROR: Could not import functions from 'utils.py'.\")\n",
        "\n",
        "# ‚úÖ Verify `purpose.py` imports\n",
        "try:\n",
        "    from travel_story import generate_travel_story, generate_voiceover, create_travel_video\n",
        "    print(\"‚úÖ Successfully imported functions from purpose.py\")\n",
        "    print(f\"generate_travel_story function exists: {callable(generate_travel_story)}\")\n",
        "    print(f\"generate_voiceover function exists: {callable(generate_voiceover)}\")\n",
        "    print(f\"create_travel_video function exists: {callable(create_travel_video)}\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"‚ùå ERROR: 'purpose.py' not found.\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå ERROR: Could not import functions from 'purpose.py'.\")\n",
        "\n",
        "# ‚úÖ Verify `app.py` existence\n",
        "if os.path.exists(\"app.py\"):\n",
        "    print(\"‚úÖ 'app.py' exists and is ready to run.\")\n",
        "else:\n",
        "    print(\"‚ùå ERROR: 'app.py' is missing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNg7J9YqcYLO",
        "outputId": "4d641295-694c-4c37-aff4-ad187b72a673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "^C\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Public URL: NgrokTunnel: \"https://5b6f-34-142-234-104.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.142.234.104:8502\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "!kill $(pgrep -f ngrok)\n",
        "\n",
        "# Run Streamlit app\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "# Set up ngrok\n",
        "!ngrok authtoken 2suOuuxs3zjz3pWQWDl9dQZPTLR_5FKMVwXpnfPJDKgESoGpK\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Run the Streamlit app\n",
        "!streamlit run app.py &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHT2y3sZdbjI"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from travel_story import generate_travel_story, generate_voiceover\n",
        "\n",
        "travel_story_text = generate_travel_story(\"New York\", \"New Delhi\", \"Family\", \"2025-04-15\", \"2025-04-20\")\n",
        "narration_audio = generate_voiceover(travel_story_text)\n",
        "\n",
        "y, sr = librosa.load(narration_audio, sr=None)\n",
        "\n",
        "# Plot the waveform\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveshow(y, sr=sr, alpha=0.6)\n",
        "plt.title(\"Voiceover Waveform\")\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGOSdF_TN2mo"
      },
      "outputs": [],
      "source": [
        "# Let's say you want to zoom in on the first 10 seconds\n",
        "zoom_start = 0\n",
        "zoom_end = int(10 * sr)  # 10 seconds worth of samples\n",
        "y_zoom = y[zoom_start:zoom_end]\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.waveshow(y_zoom, sr=sr, alpha=0.6)\n",
        "plt.title(\"Zoomed-in Waveform (First 10 Seconds)\")\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZEYRgmrN9Rp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the Short-Time Fourier Transform (STFT)\n",
        "D = np.abs(librosa.stft(y))\n",
        "# Convert amplitude to decibels\n",
        "DB = librosa.amplitude_to_db(D, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.specshow(DB, sr=sr, x_axis='time', y_axis='hz')\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.title(\"Spectrogram\")\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Frequency (Hz)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYVXe9DNOK24"
      },
      "outputs": [],
      "source": [
        "# Compute RMS energy\n",
        "rms = librosa.feature.rms(y=y)[0]\n",
        "# Convert frame indices to time\n",
        "frames = range(len(rms))\n",
        "t = librosa.frames_to_time(frames, sr=sr)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot the raw waveform with reduced opacity\n",
        "librosa.display.waveshow(y, sr=sr, alpha=0.4, label='Waveform')\n",
        "\n",
        "# Overlay the RMS energy\n",
        "plt.plot(t, rms, color='r', label='RMS Energy')\n",
        "\n",
        "plt.title(\"Waveform with RMS Energy\")\n",
        "plt.xlabel(\"Time (seconds)\")\n",
        "plt.ylabel(\"Amplitude / RMS\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
